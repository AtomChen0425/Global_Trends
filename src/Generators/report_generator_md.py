import os
import time
import logging
from datetime import datetime
from src.FetchPipeline.fetch_from_web import fetch_url_content

# å°è¯•å¯¼å…¥ Gemini AI å·¥å…·
try:
    from src.utils.AI_Agent import gemini_summarize
    GEMINI_AVAILABLE = True
    GEMINI_RATE_LIMIT_DELAY = 2.0  # é¿å…è§¦å‘ API é¢‘ç‡é™åˆ¶
except ImportError:
    GEMINI_AVAILABLE = False
    logging.getLogger(__name__).warning("Gemini AI_Agent æ¨¡å—æœªæ‰¾åˆ°ï¼Œå°†ä»…ä½¿ç”¨åŸæ–‡æ‘˜è¦ã€‚")

logger = logging.getLogger(__name__)

def _get_ai_summary(content: str, prompt_name: str, item_id: str) -> str:
    """
    é€šç”¨ AI æ‘˜è¦è·å–å‡½æ•°
    """
    if not content or not GEMINI_AVAILABLE:
        return ""
    
    try:
        logger.info(f"[{item_id}] æ­£åœ¨ç”Ÿæˆ AI æ‘˜è¦...")
        summary = gemini_summarize(content, prompt_name)
        time.sleep(GEMINI_RATE_LIMIT_DELAY)
        return summary
    except Exception as e:
        logger.error(f"[{item_id}] AI æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
        return ""

def _format_expandable_block(text: str, label: str = "ğŸ¤– AI æ‘˜è¦", cutoff: int = 90) -> str:
    """
    ç”Ÿæˆâ€œæ— ç¼å±•å¼€â€çš„ HTML å—
    å°†æ–‡æœ¬åˆ‡åˆ†ä¸º Head (æ‘˜è¦å¯è§éƒ¨åˆ†) å’Œ Tail (æŠ˜å éƒ¨åˆ†)
    """
    if not text:
        return ""

    if len(text) <= cutoff:
        # æ–‡æœ¬å¾ˆçŸ­ï¼Œç›´æ¥æ˜¾ç¤º
        return f"> <strong>{label}:</strong> {text}\n"

    # åˆ‡å‰²æ–‡æœ¬
    head = text[:cutoff]
    # tail = text[cutoff:]
    
    # è½¬ä¹‰ summary æ ‡ç­¾ä¸­çš„ç‰¹æ®Šå­—ç¬¦ï¼Œé˜²æ­¢ HTML æ¸²æŸ“é”™è¯¯
    head_safe = head.replace('"', "'").replace("<", "&lt;").replace(">", "&gt;")

    html = [
        f"<details>",
        f"<summary><strong>{label}:</strong> {head_safe}...</summary>",
        f"\n{text}\n", 
        f"</details>\n"
    ]
    return "\n".join(html)

def generate_report_CN(intel: dict) -> str:
    date_str = datetime.now().strftime("%Y-%m-%d")
    
    lines = [
        f"# ğŸŒ Global Tech Intelligence Briefing - {date_str}",
        f"**æ—¥æœŸ:** {date_str}",
        f"**ç”Ÿæˆæ—¶é—´:** {datetime.now().strftime('%H:%M')}",
        f"**æ•°æ®æº:** Hacker News, GitHub Trending, ArXiv",
        "",
        "---",
        ""
    ]

    # --- 1. Hacker News ---
    lines.append("## ğŸ“° Hacker News (Top Stories)")
    if intel.get("hn"):
        for i, item in enumerate(intel["hn"], 1):
            title = item.get("title", "Untitled").replace("|", "&#124;")
            url = item.get("url", "#")
            score = item.get("score", 0)
            time_str = item.get("time", "")
            
            lines.append(f"### {i}. [{title}]({url})")
            lines.append(f"ğŸ”¥ {score} | ğŸ•’ {time_str}")
            
            # è·å–å†…å®¹ -> AI æ€»ç»“ -> æ ¼å¼åŒ–
            content = fetch_url_content(url)
            if content:
                # ä¼˜å…ˆç”¨ AI æ‘˜è¦ï¼Œå¦‚æœæ²¡æœ‰åˆ™æˆªå–åŸæ–‡
                ai_summary = _get_ai_summary(content, "TechDoc_Summarize_CN", f"HN-{i}")
                display_text = ai_summary if ai_summary else content[:500] + "..."
                
                # æ·»åŠ æŠ˜å å—
                lines.append(_format_expandable_block(display_text, label="ğŸ“– æ‘˜è¦"))
            
            lines.append("---")
    else:
        lines.append("*æš‚æ— æ•°æ®*\n")

    # --- 2. GitHub Trending ---
    lines.append("## ğŸš€ GitHub Trending")
    lines.append("> è¿‡å» 24 å°æ—¶é«˜æ˜Ÿå¢é•¿é¡¹ç›®\n")
    if intel.get("github"):
        for i, item in enumerate(intel["github"], 1):
            title = item.get("title", "Untitled")
            url = item.get("url", "#")
            stars = item.get("stars", 0)
            desc = item.get("description", "æš‚æ— æè¿°").strip().replace("\n", " ")
            readme = item.get("readme", "").strip()
            
            lines.append(f"### {i}. [{title}]({url})")
            lines.append(f"â­ **Stars:** {stars}")
            lines.append(f"> ğŸ“ {desc}\n")
            
            if readme:
                ai_summary = _get_ai_summary(readme, "Github_Summarize_CN", f"GH-{i}")
                display_text = ai_summary if ai_summary else readme[:500] + "..."
                lines.append(_format_expandable_block(display_text, label="ğŸ¤– æ™ºèƒ½è§£æ"))
            
            lines.append("---")
    else:
        lines.append("*æš‚æ— æ•°æ®*\n")

    # --- 3. GitHub Latest ---
    lines.append("## âœ¨ GitHub (New & Shiny)")
    if intel.get("latest_github"):
        for i, item in enumerate(intel["latest_github"], 1):
            title = item.get("title", "Untitled")
            url = item.get("url", "#")
            stars = item.get("stars", 0)
            desc = item.get("description", "æš‚æ— æè¿°").strip().replace("\n", " ")
            readme = item.get("readme", "").strip()
            
            lines.append(f"### {i}. [{title}]({url})")
            lines.append(f"â­ **Stars:** {stars}")
            lines.append(f"> ğŸ“ {desc}\n")
            
            if readme:
                ai_summary = _get_ai_summary(readme, "Github_Summarize_CN", f"GH-New-{i}")
                display_text = ai_summary if ai_summary else readme[:500] + "..."
                lines.append(_format_expandable_block(display_text, label="ğŸ¤– æ™ºèƒ½è§£æ"))

            lines.append("---")
    else:
        lines.append("*æš‚æ— æ•°æ®*\n")

    # --- 4. ArXiv Papers ---
    lines.append("## ğŸ“š Latest Paper (ArXiv AI/CV Papers)")
    lines.append("> æœ€æ–°äººå·¥æ™ºèƒ½ä¸è®¡ç®—æœºè§†è§‰è®ºæ–‡\n")
    if intel.get("arxiv"):
        for i, item in enumerate(intel["arxiv"], 1):
            title = item.get("title", "Untitled")
            url = item.get("url", "#")
            authors = item.get("authors", "")
            summary = item.get("summary", "").replace("\n", " ")
            
            lines.append(f"### {i}. [{title}]({url})")
            lines.append(f"ğŸ‘¤ **Authors:** {authors}")
            
            if summary:
                ai_summary = _get_ai_summary(summary, "TechDoc_Summarize_CN", f"ArXiv-{i}")
                display_text = ai_summary if ai_summary else summary
                lines.append(_format_expandable_block(display_text, label="ğŸ“„ è®ºæ–‡æ‘˜è¦"))

            lines.append("---")
    else:
        lines.append("*æš‚æ— æ•°æ®*\n")

    return "\n".join(lines)
def generate_report_EN(intel: dict) -> str:
    date_str = datetime.now().strftime("%Y-%m-%d")
    
    lines = [
        f"# ğŸŒ Global Tech Intelligence Briefing - {date_str}",
        f"**Date:** {date_str}",
        f"**Generated At:** {datetime.now().strftime('%H:%M')}",
        f"**Data Sources:** Hacker News, GitHub Trending, ArXiv",
        "",
        "---",
        ""
    ]

    # --- 1. Hacker News ---
    lines.append("## ğŸ“° Hacker News (Top Stories)")
    if intel.get("hn"):
        for i, item in enumerate(intel["hn"], 1):
            title = item.get("title", "Untitled").replace("|", "&#124;")
            url = item.get("url", "#")
            score = item.get("score", 0)
            time_str = item.get("time", "")
            
            lines.append(f"### {i}. [{title}]({url})")
            lines.append(f"ğŸ”¥ {score} | ğŸ•’ {time_str}")
            
            # è·å–å†…å®¹ -> AI æ€»ç»“ -> æ ¼å¼åŒ–
            content = fetch_url_content(url)
            if content:
                # ä¼˜å…ˆç”¨ AI æ‘˜è¦ï¼Œå¦‚æœæ²¡æœ‰åˆ™æˆªå–åŸæ–‡
                ai_summary = _get_ai_summary(content, "TechDoc_Summarize", f"HN-{i}")
                display_text = ai_summary if ai_summary else content[:500] + "..."
                
                # æ·»åŠ æŠ˜å å—
                lines.append(_format_expandable_block(display_text, label="ğŸ“– Summary"))
            
            lines.append("---")
    else:
        lines.append("*No data available*\n")

    # --- 2. GitHub Trending ---
    lines.append("## ğŸš€ GitHub Trending")
    lines.append("> Projects with the highest star growth in the past 24 hours\n")
    if intel.get("github"):
        for i, item in enumerate(intel["github"], 1):
            title = item.get("title", "Untitled")
            url = item.get("url", "#")
            stars = item.get("stars", 0)
            desc = item.get("description", "No description available").strip().replace("\n", " ")
            readme = item.get("readme", "").strip()
            
            lines.append(f"### {i}. [{title}]({url})")
            lines.append(f"â­ **Stars:** {stars}")
            lines.append(f"> ğŸ“ {desc}\n")
            
            if readme:
                ai_summary = _get_ai_summary(readme, "Github_Summarize", f"GH-{i}")
                display_text = ai_summary if ai_summary else readme[:500] + "..."
                lines.append(_format_expandable_block(display_text, label="ğŸ¤– AI Summary"))
            
            lines.append("---")
    else:
        lines.append("*No data available*\n")

    # --- 3. GitHub Latest ---
    lines.append("## âœ¨ GitHub (New & Shiny)")
    if intel.get("latest_github"):
        for i, item in enumerate(intel["latest_github"], 1):
            title = item.get("title", "Untitled")
            url = item.get("url", "#")
            stars = item.get("stars", 0)
            desc = item.get("description", "No description available").strip().replace("\n", " ")
            readme = item.get("readme", "").strip()
            
            lines.append(f"### {i}. [{title}]({url})")
            lines.append(f"â­ **Stars:** {stars}")
            lines.append(f"> ğŸ“ {desc}\n")
            
            if readme:
                ai_summary = _get_ai_summary(readme, "Github_Summarize", f"GH-New-{i}")
                display_text = ai_summary if ai_summary else readme[:500] + "..."
                lines.append(_format_expandable_block(display_text, label="ğŸ¤– AI Summary"))

            lines.append("---")
    else:
        lines.append("*No data available*\n")

    # --- 4. ArXiv Papers ---
    lines.append("## ğŸ“š Latest Paper (ArXiv AI/CV Papers)")
    lines.append("> Latest AI and Computer Vision Papers\n")
    if intel.get("arxiv"):
        for i, item in enumerate(intel["arxiv"], 1):
            title = item.get("title", "Untitled")
            url = item.get("url", "#")
            authors = item.get("authors", "")
            summary = item.get("summary", "").replace("\n", " ")
            
            lines.append(f"### {i}. [{title}]({url})")
            lines.append(f"ğŸ‘¤ **Authors:** {authors}")
            
            if summary:
                ai_summary = _get_ai_summary(summary, "TechDoc_Summarize", f"ArXiv-{i}")
                display_text = ai_summary if ai_summary else summary
                lines.append(_format_expandable_block(display_text, label="ğŸ“„ Paper Summary"))

            lines.append("---")
    else:
        lines.append("*No data available*\n")

    return "\n".join(lines)

def save_report(content: str, output_dir: str = "reports",lang='CN') -> str:
    """ä¿å­˜ Markdown æŠ¥å‘Š"""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    date_str = datetime.now().strftime("%Y-%m-%d")
    file_path = os.path.join(output_dir, f"Daily_Briefing_{date_str}_{lang}.md")
    with open(file_path, "w", encoding="utf-8") as f:
        f.write(content)
    logger.info(f"âœ… æŠ¥å‘Šå·²ä¿å­˜: {file_path}")
    return file_path